
![teaser image](https://cloud.githubusercontent.com/assets/15609655/18515925/5095d284-7a97-11e6-9276-75e9230dccbe.jpg)

# Sample Dasboard Application running on MarkLogic built using MarkLogic-Node (Slush) generator

# MarkLogic capabilities demonstrated in this application

## Incredibely fast integration of data from different sources/silos with siginificantly reduced ETL needs
- Loading data as-is from external data sources (RSS, Twitter, Quandl)
- Peaceful coexistence of JSON and XML data in the same database, used in the same application
- [Envelope pattern](https://developer.marklogic.com/learn/data-modeling)

## Rich set of tools that support/facilitate getting data into MarkLogic
- Using db [tasks](https://docs.marklogic.com/guide/admin/getting_started#id_49240) to schedule re-ocurring jobs (such as pulling in data updates here)
- Using [mlcp](https://docs.marklogic.com/guide/mlcp/import) to load and parse PDF documents

## Unparalleled data search and querying capabilities of MarkLogic's universal and scalar indexes
- MarkLogic Search capabilities including free-text and structured search, facets and dynamic date bucketing
- Combining multiple JSON properties and XML elements into single Fields and defining [Field range index](https://docs.marklogic.com/guide/admin/range_index#id_14554)
- Customizing the Search API to perform a on-the-fly transform of the search response
- [Highlighting](https://docs.marklogic.com/cts:highlight) of matched keywords
- Building word clouds based on [distinctive terms](https://docs.marklogic.com/guide/search-dev/similar) function

## Using and extending MarkLogic application server's capabilities to expose new functionality
- MarkLogic mathematical functions (to calculate winner/loser stock of the day/week)
- Using both XQuery and Server-side JavaScript to write server-side code
- Exposing server-side functions as REST API to be consumed by the front end

## Rapid development of UI/web applications on top of MarkLogic used the Slush node-generator stack
- Some UI goodies provided by the Slush generator: Tag Cloud, AngularJS Highcharts, document viewer (PDF and HTML)
- Last but not least: incredibly short time it takes to build such an application with MarkLogic and Slush: total effort was 12 person/days

# Cool! How can I deploy this application locally on my computer??

This application was generated by the MarkLogic-Node [Slush](https://github.com/klei/slush) generator, with the following components:

- [AngularJS](https://angularjs.org/)
- [Gulp](http://gulpjs.com/)
- [node.js](http://nodejs.org/): very thin layer, hosting the Angular code and proxying MarkLogic REST API requests
- [Roxy Deployer](https://github.com/marklogic/roxy): bootstrap MarkLogic databases, application servers, etc; scaffolding for MarkLogic REST API service extensions

## Install Required Dependencies

- [node.js](http://nodejs.org/download/)
- [npm](https://www.npmjs.com/): Built-in package manager for node (comes with
  node, but check to be sure you have latest version: `npm install -g npm`)
- [gulp](http://gulpjs.com/): Javascript task automation (`npm install -g gulp`)
- [Bower](http://bower.io/): A package manager for front-end libraries (`npm install -g bower`)
- [Git](https://git-scm.com/) - Roxy depends on this version control system
- [Ruby](https://www.ruby-lang.org/en/documentation/installation/) - Roxy
  depends on Ruby in order to run server configuration scripts

# Change setting in deploy/local.properties
Change ports, username/password for your local deployment

# Running the application

    ./ml local bootstrap
    ./ml local deploy modules

On Windows, that would be:

    ml.bat local bootstrap
    ml.bat local deploy modules

Install additional dependencies using the bower package manager:

    bower install

Edit `./local.json` to set your desired ports

To run the web-server

    gulp serve-local # this will watch the .less file for changes, compile them to .css, and run the node server

# Installation and deployment on server

See etc/INSTALL.md

# Data

To do a initial insert of data or a one-time, manual update, run 

    ./import-data.sh
    ./import-internal-docs.sh

This script will call other scripts that update data per data source.

Data used in this demo include RSS feeds from 2 sources (finanzen.net and handelsblatt), Twitter status updates from 4 sources (@Bankenverband, @ECB, @IIF, @bundesbank) and prices of stock listed in the Frankfurt stock market's DAX index.

Tasks defined in src/tasks take care of perioducally updated data from these data sources so the amaount of data in the database will grow over time.

# Adding new data sources

To add new data sources, go to config page (/config). When adding an RSS source, make sure you add the correct encoding.
For new Twitter sources, add a new Twitter screen name.

Click on "Save" button when done to update the configuration file ("/config/sources.json" in the main/document dB)

New sources will be ingested at the next scheduled task run. If you want to ingest data from newly added sources immediatelly, run:

    ./import-data.sh

from the command line.